{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b708ee07",
   "metadata": {},
   "source": [
    "# 🎨 모델 맞춤화 소개\n",
    "\n",
    "## 🛒 Zava 시나리오\n",
    "\n",
    "Cora는 기본 모델로 잘 작동하고 있지만, Zava는 자사 브랜드의 어조, 주택 개량 관련 용어, 고객 서비스 지침에 더욱 부합하는 응답을 제공하기를 원합니다. 일반적인 모델은 주택 개량 소매업의 특수한 뉘앙스를 제대로 반영하지 못할 수 있습니다.\n",
    "\n",
    "**기회**: 단순히 즉각적인 엔지니어링에만 의존하는 대신, 미세 조정 및 정제와 같은 기법을 통해 Cora 모델을 Zava의 주택 개량 소매업 요구사항에 더욱 특화시켜 맞춤화할 수 있습니다.\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "이 섹션에서는 다음 내용을 이해하게 됩니다.\n",
    "\n",
    "1. **소규모 프롬프트(Few-shot prompting)** - 프롬프트의 예시를 통해 모델을 학습시키는 방법\n",
    "2. **지도 미세 조정(Supervised Fine-Tuning, SFT)** - 도메인별 데이터를 사용하여 모델을 학습시키는 방법\n",
    "3. **데이터 정제(Distillation)** - 규모가 큰 모델에서 작은 모델로 지식을 이전하는 방법\n",
    "4. **미세 조정을 위한 데이터 준비** - JSONL 형식 및 모범 사례\n",
    "5. **각 사용자 지정 기법의 사용 시점** - 장단점 및 사용 사례\n",
    "\n",
    "## 왜 이것이 중요한가?\n",
    "\n",
    "모델 사용자 지정을 통해 다음과 같은 이점을 얻을 수 있습니다.\n",
    "- **도메인별 작업에 대한 응답 품질 향상**\n",
    "- **더 작고 특화된 모델 사용**으로 **비용 절감**\n",
    "- **브랜드 보이스 및 가이드라인에 맞춘 출력**\n",
    "- **비즈니스 고유의 전문 용어 처리**\n",
    "\n",
    "Zava의 주택 개량 소매 사업에 Cora를 더욱 효과적으로 활용하기 위해 모델을 사용자 지정하는 방법을 살펴보겠습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e8cba",
   "metadata": {},
   "source": [
    "## 모델을 맞춤 설정하는 이유\n",
    "\n",
    "기본 모델(GPT-4o, GPT-4o-mini)은 일반 인터넷 데이터를 기반으로 학습됩니다. 강력하지만 범용성이 떨어집니다.\n",
    "\n",
    "**기본 모델의 문제점:**\n",
    "\n",
    "### 1. 일관성 없는 어조/스타일\n",
    "\n",
    "**고객:** \"어떤 페인트가 있나요?\"\n",
    "\n",
    "**기본 모델:** \"저희는 실내용, 실외용, 라텍스, 유성 등 다양한 페인트 옵션을 보유하고 있습니다...\"\n",
    "\n",
    "**맞춤 모델(Zava 스타일):** \"좋은 질문입니다! 고객님의 프로젝트에 적합한 훌륭한 페인트 옵션이 여러 가지 있습니다. 완벽한 색상을 찾도록 도와드리겠습니다...\"\n",
    "\n",
    "맞춤 모델은 Zava의 친절하고 도움이 되는 브랜드 어조를 일관되게 유지합니다.\n",
    "\n",
    "### 2. 전문 지식 부족\n",
    "\n",
    "**고객:** \"T1-11 사이딩에 사용할 페인트가 필요합니다.\"\n",
    "\n",
    "**기본 모델:** \"페인트를 찾는 데 도움을 드릴 수 있습니다. 어떤 색상을 찾으시나요?\"\n",
    "\n",
    "**맞춤 모델:** \"T1-11 사이딩에는 침투력이 좋은 고품질 외장용 아크릴 라텍스 페인트가 필요합니다. 저희 프리미엄 외장 페인트(PFIP000002)가 이 용도에 딱 맞습니다...\"\n",
    "\n",
    "맞춤 모델은 하드웨어/건축 용어를 이해합니다.\n",
    "\n",
    "### 3. 긴 프롬프트\n",
    "\n",
    "**맞춤 설정이 없는 경우:** 모든 프롬프트에 예시를 포함해야 합니다.\n",
    "```\n",
    "프롬프트(500 토큰):\n",
    "\"당신은 친절한 Zava 도우미 Cora입니다. 예시:\n",
    "질문: 어떤 페인트를 사용하시나요? 답변: [예시]\n",
    "질문: 어떤 드릴을 사용하시나요? 답변: [예시]\n",
    "...\n",
    "이제 다음 질문에 답해 주세요: 어떤 페인트를 가지고 계신가요?\"\n",
    "``\n",
    "\n",
    "**맞춤 설정이 있는 경우:** 모델이 이미 스타일을 \"알고\" 있습니다.\n",
    "```\n",
    "프롬프트(50 토큰):\n",
    "\"당신은 Cora입니다. 고객이 묻습니다: 어떤 페인트를 가지고 계신가요?\"\n",
    "```\n",
    "\n",
    "**결과:** 토큰 수의 상당한 감소로 대규모 운영 시 비용 절감\n",
    "\n",
    "### 4. 응답 일관성\n",
    "\n",
    "**기본 모델 응답의 다양성:**\n",
    "- 질의 1: 공식적이고 기술적인 내용\n",
    "- 질의 2: 비공식적이고 간략한 내용\n",
    "- 질의 3: 지나치게 상세한 내용\n",
    "\n",
    "**맞춤형 모델:** 모든 응답에서 일관된 어조, 구조 및 상세 수준 유지\n",
    "\n",
    "## 맞춤 설정 접근 방식\n",
    "\n",
    "모델 동작을 맞춤 설정하는 주요 방법은 세 가지입니다.\n",
    "\n",
    "| 접근 방식 | 기능 | 최적 사용 분야 | 비용 | 노력 |\n",
    "----------|--------------|----------|------|--------|\n",
    "**소규모 질의 응답(Few-Shot Prompting)** | 질의 응답에 예시 포함 | 빠른 테스트, 동적 예시 | 낮은 비용(토큰당 지불) | 낮은 비용 |\n",
    "**미세 조정** | 자체 데이터로 모델 학습 | 일관된 스타일, 도메인 지식 | 중간 비용(일회성 학습) | 중간 비용 |\n",
    "**핵심 정보 추출** | 대규모 모델의 지식 이전 | 비용 최적화, 효율성 | 낮음-중간 | 높음 |\n",
    "\n",
    "각 항목을 자세히 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8182bc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Few-Shot Prompting\n",
    "\n",
    "**Few-shot prompting**이란 모델의 동작을 안내하기 위해 프롬프트에 예시 쿼리-응답 쌍을 포함하는 것을 의미합니다.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "You are Cora, a helpful Zava Hardware assistant.\n",
    "\n",
    "Example 1:\n",
    "Customer: What paint do you have?\n",
    "Cora: Great question! We have several excellent paint options. For interior \n",
    "projects, I recommend our Premium Interior Paint. For exterior, our Premium \n",
    "Exterior Paint is weather-resistant and durable. What's your project?\n",
    "\n",
    "Example 2:\n",
    "Customer: Is PFIP000002 in stock?\n",
    "Cora: Yes! Premium Exterior Paint (SKU: PFIP000002) is currently in stock \n",
    "with 75 units available. Would you like me to help you with anything else?\n",
    "\n",
    "Now answer:\n",
    "Customer: {user_query}\n",
    "Cora:\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**이 모델은 예시를 통해 학습하고 스타일을 모방합니다.\n",
    "\n",
    "### Pros\n",
    "\n",
    "✅ **빠른 구현** - 교육 불필요\n",
    "✅ **유연성** - 언제든지 예시 변경 가능\n",
    "✅ **인프라 불필요** - 프롬프트만 수정하면 됨\n",
    "✅ **동적** - 시나리오별로 다른 예시 제공\n",
    "\n",
    "### 단점\n",
    "\n",
    "❌ **토큰 비용 증가** - 예시 추가 시 요청당 200~500 토큰 추가\n",
    "❌ **컨텍스트 윈도우 사용** - 실제 대화 공간 부족\n",
    "❌ **일관성 부족** - 모델이 여전히 즉흥적으로 작동함\n",
    "❌ **제한된 예시** - 5~10개 예시만 가능\n",
    "\n",
    "### Few-Shot을 언제 사용하는가\n",
    "\n",
    "- ✅ 프로토타이핑 및 테스트\n",
    "- ✅ 유연성 필요 (예시가 자주 변경됨)\n",
    "- ✅ 낮은 쿼리량 (< 하루 1,000건)\n",
    "- ✅ 간단한 동작 변경\n",
    "- ❌ 높은 쿼리량 (비용 부담)\n",
    "- ❌ 완벽한 일관성 필요\n",
    "- ❌ 복잡한 도메인 지식 필요\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "**Scenario:** 10,000 queries/day with 5 examples (300 tokens)\n",
    "\n",
    "```\n",
    "소량 데이터 처리 방식:\n",
    "- 요청당 토큰 사용량 증가(예제 포함)\n",
    "- 사용량 기반 요금제\n",
    "- 비용은 처리량에 비례하여 증가\n",
    "\n",
    "정밀 조정 방식:\n",
    "- 요청당 토큰 사용량 감소(예제 불필요)\n",
    "- 일회성 학습 비용\n",
    "- 요청당 추론 비용 감소\n",
    "\n",
    "처리량이 많을수록 정밀 조정 방식이 더 비용 효율적입니다.\n",
    "\n",
    "**결론:** 소량 데이터 처리에는 소량 데이터 처리 방식이 적합하고, 대규모 처리에는 정밀 조정 방식이 더 효과적입니다.\n",
    "\n",
    "For current pricing: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b6eea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fine-Tuning\n",
    "\n",
    "**Fine-tuning**은 사용자의 특정 데이터를 기반으로 기본 모델을 지속적으로 학습시키고, 내부 매개변수를 조정하여 사용자의 도메인과 스타일을 학습시키는 것을 의미합니다.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Base Model (GPT-4o-mini)\n",
    "         ↓\n",
    "    + Your Training Data\n",
    "      (100-1000 examples)\n",
    "         ↓\n",
    "   Fine-Tuning Process\n",
    "   (2-6 hours on Azure)\n",
    "         ↓\n",
    "   Custom Fine-Tuned Model\n",
    "   (your-model-deployment)\n",
    "```\n",
    "\n",
    "**모델의 가중치가 업데이트**되어 패턴을 직접 인코딩합니다.\n",
    "\n",
    "### What Gets Trained\n",
    "\n",
    "**Training data format (JSONL):**\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora, a Zava assistant\"}, {\"role\": \"user\", \"content\": \"What paint do you have?\"}, {\"role\": \"assistant\", \"content\": \"Great question! We have several excellent paint options...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora, a Zava assistant\"}, {\"role\": \"user\", \"content\": \"Is PFIP000002 in stock?\"}, {\"role\": \"assistant\", \"content\": \"Yes! Premium Exterior Paint is currently in stock...\"}]}\n",
    "```\n",
    "\n",
    "각 줄은 다음과 같은 내용을 보여주는 완전한 대화 예시입니다.\n",
    "1. 시스템 지시사항\n",
    "2. 사용자 질문\n",
    "3. 예상되는 어시스턴트 응답\n",
    "\n",
    "**모델은 다음을 학습합니다.**\n",
    "- 응답 스타일 및 어조\n",
    "- 도메인 용어\n",
    "- 응답 구조 및 형식\n",
    "- 브랜드 보이스 및 개성\n",
    "\n",
    "### Supervised Fine-Tuning (SFT)\n",
    "\n",
    "**SFT**는 가장 일반적인 미세 조정 접근 방식입니다.\n",
    "\n",
    "1. **지도 학습** - 레이블이 지정된 예제(질문 → 예상 응답)를 제공합니다.\n",
    "2. **학습 목표** - 모델은 입력값을 기반으로 응답을 예측하도록 학습합니다.\n",
    "3. **경사 하강법** - 모델 가중치를 조정하여 데이터에 대한 오류를 최소화합니다.\n",
    "\n",
    "**비유:** 연습 문제와 정답을 통해 학생을 지도하는 것과 같습니다.\n",
    "\n",
    "### 학습 데이터 준비\n",
    "\n",
    "**데이터 요구 사항:**\n",
    "- **최소:** 50개 예제 (많을수록 좋음)\n",
    "- **권장:** 100~1000개 예제\n",
    "- **형식:** JSONL (JSON 라인)\n",
    "- **품질:** 고품질 예제만 사용\n",
    "\n",
    "**데이터 소스:**\n",
    "1. **실제 대화** (가능한 경우)\n",
    "2. **합성 생성** (Azure AI 시뮬레이터 사용)\n",
    "3. **수동 큐레이션** (전문가가 작성한 예제)\n",
    "4. **하이브리드** (실제 + 증강)\n",
    "\n",
    "**Example generation:**\n",
    "\n",
    "```python\n",
    "training_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"What paint is best for kitchens?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"For kitchens, I recommend our Premium Interior Paint...\"}\n",
    "        ]\n",
    "    },\n",
    "    # ... 99 more examples\n",
    "]\n",
    "\n",
    "# Save as JSONL\n",
    "with open(\"training.jsonl\", \"w\") as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "```\n",
    "\n",
    "### Token Optimization\n",
    "\n",
    "**Problem:** 토큰 개수에 따른 학습 비용\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Training Cost = (Total Tokens in Dataset) × (Training Epochs) × (Price per Token)\n",
    "```\n",
    "\n",
    "**Optimization strategies:**\n",
    "\n",
    "1. **Remove redundancy**\n",
    "```python\n",
    "# Before (verbose)\n",
    "\"Hello! Thank you for asking! I'm happy to help you with that question...\"\n",
    "\n",
    "# After (concise)\n",
    "\"I recommend our Premium Exterior Paint for outdoor wood projects...\"\n",
    "```\n",
    "\n",
    "2. **Truncate long responses**\n",
    "```python\n",
    "# Keep responses under 150 tokens\n",
    "if token_count(response) > 150:\n",
    "    response = truncate_intelligently(response, 150)\n",
    "```\n",
    "\n",
    "3. **Validate before uploading**\n",
    "```python\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Check token counts\n",
    "total_tokens = sum(count_tokens(ex) for ex in training_data)\n",
    "cost_estimate = (total_tokens * epochs * price_per_1k) / 1000\n",
    "\n",
    "print(f\"Estimated training cost: ${cost_estimate:.2f}\")\n",
    "```\n",
    "\n",
    "### Fine-Tuning Process\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Prepare data** (JSONL format)\n",
    "2. **Upload to Azure OpenAI**\n",
    "3. **Submit fine-tuning job**\n",
    "4. **Monitor progress** (2-6 hours)\n",
    "5. **Deploy fine-tuned model**\n",
    "6. **Test and validate**\n",
    "\n",
    "**Azure OpenAI fine-tuning job:**\n",
    "\n",
    "```python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(...)\n",
    "\n",
    "# Upload training file\n",
    "with open(\"training.jsonl\", \"rb\") as f:\n",
    "    training_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "# Create fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3  # Number of training passes\n",
    "    }\n",
    ")\n",
    "\n",
    "# Monitor\n",
    "status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(f\"Status: {status.status}\")\n",
    "```\n",
    "\n",
    "### 장점\n",
    "\n",
    "✅ **짧은 프롬프트** - 예시 불필요\n",
    "✅ **일관된 동작** - 모델이 사용자의 스타일을 파악\n",
    "✅ **향상된 도메인 지식** - 전문 용어 학습\n",
    "✅ **대규모 환경에서 비용 효율성** - 쿼리당 비용 절감\n",
    "✅ **향상된 품질** - 특정 사용 사례에 특화\n",
    "\n",
    "### 단점\n",
    "\n",
    "❌ **초기 노력** - 학습 데이터 생성 필요\n",
    "❌ **학습 시간** - 작업당 2~6시간\n",
    "❌ **정적 지식** - 업데이트 시 재학습 필요\n",
    "❌ **복잡한 버전 관리** - 모델 버전 관리 필요\n",
    "\n",
    "### 미세 조정 사용 시점\n",
    "\n",
    "- ✅ 높은 쿼리량 (하루 1,000건 이상)\n",
    "- ✅ 일관된 어조/스타일 필요\n",
    "- ✅ 도메인별 전문 용어 필요\n",
    "- ✅ 고품질 학습 데이터 보유\n",
    "- ✅ 장기 배포\n",
    "- ❌ 데이터가 매일 변경되는 경우\n",
    "- ❌ 실시간 업데이트가 필요합니다\n",
    "- ❌ 조회량이 매우 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b539278",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Distillation\n",
    "\n",
    "**Distillation**은 더 작고 빠른 모델을 훈련시켜 더 크고 성능이 뛰어난 모델을 모방하는 것을 의미합니다.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Large \"Teacher\" Model          Small \"Student\" Model\n",
    "(Higher cost/better)    →      (Lower cost/faster)\n",
    "                                     \n",
    "Query: \"What paint?\"    →      Query: \"What paint?\"\n",
    "Response: [detailed]    →      Response: [similar quality]\n",
    "                                     \n",
    "Cost: Higher per token         Cost: Lower per token\n",
    "Latency: Slower                Latency: Faster\n",
    "\n",
    "See pricing: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "```\n",
    "\n",
    "**Goal:** GPT-4o 수준의 품질을 GPT-4o-mini 수준의 비용/속도로 누리세요.\n",
    "\n",
    "### Distillation Process\n",
    "\n",
    "**Step 1: Generate Teacher Responses**\n",
    "\n",
    "```python\n",
    "# Use large model to generate high-quality responses\n",
    "teacher_model = \"gpt-4o\"\n",
    "student_training_data = []\n",
    "\n",
    "for query in training_queries:\n",
    "    teacher_response = call_model(teacher_model, query)\n",
    "    student_training_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": teacher_response}\n",
    "        ]\n",
    "    })\n",
    "```\n",
    "\n",
    "**Step 2: Fine-Tune Student Model**\n",
    "\n",
    "```python\n",
    "# Fine-tune small model on teacher's responses\n",
    "student_model = fine_tune(\n",
    "    base_model=\"gpt-4o-mini\",\n",
    "    training_data=student_training_data\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 3: Evaluate**\n",
    "\n",
    "```python\n",
    "# Compare student vs teacher\n",
    "for query in test_queries:\n",
    "    teacher_response = call_model(\"gpt-4o\", query)\n",
    "    student_response = call_model(student_model, query)\n",
    "    \n",
    "    similarity = compute_similarity(teacher_response, student_response)\n",
    "    print(f\"Similarity: {similarity}\")  # Goal: > 0.85\n",
    "```\n",
    "\n",
    "### Knowledge Transfer\n",
    "\n",
    "**What gets distilled:**\n",
    "- Reasoning patterns\n",
    "- Response structure\n",
    "- Domain knowledge\n",
    "- Task-specific behaviors\n",
    "\n",
    "**What doesn't get distilled:**\n",
    "- Raw intelligence (student has limits)\n",
    "- Emergent capabilities (student is smaller)\n",
    "- Perfect accuracy (some quality loss acceptable)\n",
    "\n",
    "### Types of Distillation\n",
    "\n",
    "**1. Basic Distillation**\n",
    "- Student learns from teacher's outputs directly\n",
    "- Simple, effective for most use cases\n",
    "\n",
    "**2. Distillation with Custom Graders**\n",
    "- Use custom evaluators to score teacher responses\n",
    "- Only keep high-quality examples for student training\n",
    "- Better quality control\n",
    "\n",
    "**Example: Custom grader**\n",
    "\n",
    "```python\n",
    "def grade_response(query, response):\n",
    "    \"\"\"Custom evaluator for response quality\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Check for key elements\n",
    "    if contains_product_sku(response):\n",
    "        score += 1\n",
    "    if polite_tone(response):\n",
    "        score += 1\n",
    "    if factually_grounded(response):\n",
    "        score += 1\n",
    "    if under_token_limit(response, 150):\n",
    "        score += 1\n",
    "        \n",
    "    return score >= 3  # Keep if passes quality threshold\n",
    "\n",
    "# Filter training data\n",
    "high_quality_data = [\n",
    "    ex for ex in distillation_data \n",
    "    if grade_response(ex[\"query\"], ex[\"response\"])\n",
    "]\n",
    "```\n",
    "\n",
    "### 장점\n",
    "\n",
    "✅ **비용 절감** - 비슷한 품질의 더 저렴한 모델\n",
    "✅ **속도 향상** - 더 빠른 추론\n",
    "✅ **소규모 배포** - 더 적은 리소스 요구 사항\n",
    "✅ **품질 유지** - 교사 모델의 품질을 약 85~95% 유지\n",
    "\n",
    "### 단점\n",
    "\n",
    "❌ **2단계 프로세스** - 생성 + 미세 조정\n",
    "❌ **품질 한계** - 학생 모델의 용량을 초과할 수 없음\n",
    "❌ **초기 비용** - 교사 응답 생성 비용이 높음\n",
    "❌ **복잡한 평가** - 품질 유지 검증 필요\n",
    "\n",
    "### Distillation을 언제 사용하는가\n",
    "\n",
    "- ✅ 프로덕션 환경에서 비용이 많이 드는 대형 모델을 사용하는 경우\n",
    "- ✅ 비용/지연 시간을 줄여야 하는 경우\n",
    "- ✅ 교사 모델 생성 예산이 있는 경우\n",
    "- ✅ 5~15%의 품질 저하를 허용할 수 있는 경우\n",
    "- ❌ 이미 가장 작은 모델을 사용 중인 경우\n",
    "- ❌ 최고 품질이 필요한 경우 (타협할 수 없음)\n",
    "- ❌ 쿼리량이 적은 경우 (ROI가 높은 경우) (너무 낮음)\n",
    "\n",
    "### ROI 계산 예시\n",
    "\n",
    "**시나리오:** 월 10만 건의 쿼리\n",
    "기존 방식(대형 모델):\n",
    "- 토큰당 비용 높음\n",
    "- 월별 운영 비용 높음\n",
    "\n",
    "최적화 방식(소형 모델, 미세 조정):\n",
    "- 일회성 생성 비용(교사 응답)\n",
    "- 일회성 학습 비용\n",
    "- 토큰당 추론 비용 감소\n",
    "- 월별 운영 비용 대폭 절감\n",
    "\n",
    "Result: Substantial cost savings at high volume\n",
    "\n",
    "Typical payback period: Days to weeks\n",
    "\n",
    "Annual savings: $15,000\n",
    "\n",
    "For pricing details: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "\n",
    "```\n",
    "**Conclusion:** Distillation is extremely valuable at high volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532bfc5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Choosing the Right Approach\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "```\n",
    "Start: Need to customize model behavior?\n",
    "  ↓\n",
    "  Yes → High query volume (> 1000/day)?\n",
    "         ↓\n",
    "         Yes → Using expensive model?\n",
    "                ↓\n",
    "                Yes → Use DISTILLATION\n",
    "                       (GPT-4o → GPT-4o-mini fine-tuned)\n",
    "                ↓\n",
    "                No → Use FINE-TUNING\n",
    "                      (GPT-4o-mini base → fine-tuned)\n",
    "         ↓\n",
    "         No → Need flexibility?\n",
    "               ↓\n",
    "               Yes → Use FEW-SHOT PROMPTING\n",
    "               ↓\n",
    "               No → Use FINE-TUNING\n",
    "                     (better long-term)\n",
    "```\n",
    "\n",
    "### Comparison Matrix\n",
    "\n",
    "| Factor | Few-Shot | Fine-Tuning | Distillation |\n",
    "|--------|----------|-------------|--------------|\n",
    "| **Setup Time** | Minutes | Hours | Days |\n",
    "| **Query Volume Sweet Spot** | < 1K/day | > 1K/day | > 10K/day |\n",
    "| **Consistency** | Medium | High | High |\n",
    "| **Cost at 10K queries/day** | Higher | Medium | Lower |\n",
    "| **Flexibility** | High | Low | Low |\n",
    "| **Domain Knowledge** | Limited | Good | Good |\n",
    "| **Quality** | Good | Better | Best (if done right) |\n",
    "\n",
    "### Hybrid Approaches\n",
    "\n",
    "**Combine multiple techniques:**\n",
    "\n",
    "**1. Fine-Tuning + RAG**\n",
    "- Fine-tune for tone/style (static)\n",
    "- RAG for product knowledge (dynamic)\n",
    "\n",
    "```python\n",
    "# Fine-tuned model for Zava brand voice\n",
    "model = \"zava-custom-model\"\n",
    "\n",
    "# RAG for up-to-date product info\n",
    "context = retrieve_from_search(query)\n",
    "\n",
    "# Combine\n",
    "response = model.query(\n",
    "    prompt=f\"Context: {context}\\n\\nQuestion: {query}\",\n",
    "    model=model\n",
    ")\n",
    "```\n",
    "\n",
    "**2. Few-Shot + Fine-Tuning**\n",
    "- Fine-tune for general behavior\n",
    "- Few-shot for specific edge cases\n",
    "\n",
    "```python\n",
    "# Use fine-tuned model as base\n",
    "model = \"zava-fine-tuned\"\n",
    "\n",
    "# Add few-shot for special cases\n",
    "if is_complex_query(query):\n",
    "    prompt_with_examples = add_examples(query)\n",
    "    response = model.query(prompt_with_examples)\n",
    "else:\n",
    "    response = model.query(query)\n",
    "```\n",
    "\n",
    "**3. Distillation + RAG**\n",
    "- Distill for cost/speed\n",
    "- RAG for factual grounding\n",
    "\n",
    "```python\n",
    "# Distilled GPT-4o-mini model\n",
    "model = \"zava-distilled-mini\"\n",
    "\n",
    "# Retrieve current data\n",
    "context = retrieve_from_search(query)\n",
    "\n",
    "# Query with context\n",
    "response = model.query(f\"Context: {context}\\n\\nQ: {query}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa802d99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Data Best Practices\n",
    "\n",
    "### 1. Quality Over Quantity\n",
    "\n",
    "**Better:**\n",
    "- 100개의 고품질의 다양한 예시\n",
    "- 신중하게 선별 및 검증됨\n",
    "- 실제 사용 사례를 대표함\n",
    "\n",
    "**Worse:**\n",
    "- 1000개의 저품질의 반복적인 예시\n",
    "- 검토 없이 자동 생성됨\n",
    "- 실제 쿼리를 대표하지 않음\n",
    "\n",
    "### 2. Diversity in Training Data\n",
    "\n",
    "Cover different:\n",
    "- **Query types** (questions, requests, commands)\n",
    "- **Complexity levels** (simple to multi-step)\n",
    "- **Product categories** (paint, tools, hardware)\n",
    "- **Customer intents** (search, compare, fact-check)\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"What paint?\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"Compare latex vs oil-based paint for outdoor furniture\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"Is PFIP000002 available in blue?\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "### 3. Validation Split\n",
    "\n",
    "**Don't use all data for training:**\n",
    "\n",
    "```\n",
    "Total: 1000 examples\n",
    "  ↓\n",
    "Training: 800 (80%)\n",
    "Validation: 200 (20%)\n",
    "```\n",
    "\n",
    "**Use validation set to:**\n",
    "- 과적합 감지\n",
    "- 하이퍼파라미터 조정\n",
    "- 일반화 성능 측정\n",
    "\n",
    "### 4. Consistent Formatting\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "**Keep consistent:**\n",
    "- 시스템 메시지 (모든 시스템에서 동일)\n",
    "- 응답 구조\n",
    "- 용어 및 명칭\n",
    "- 어조 및 스타일\n",
    "\n",
    "### 5. Token Budget Awareness\n",
    "\n",
    "```python\n",
    "# Check before training\n",
    "def validate_training_data(data_file):\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with open(data_file) as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            tokens = count_tokens(example)\n",
    "            total_tokens += tokens\n",
    "            \n",
    "            if tokens > 4096:  # Example too long\n",
    "                print(f\"Warning: Example exceeds limit: {tokens} tokens\")\n",
    "    \n",
    "    epochs = 3\n",
    "    cost = (total_tokens * epochs * 0.008) / 1000  # Example rate\n",
    "    \n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Estimated cost: ${cost:.2f}\")\n",
    "    \n",
    "    return total_tokens < 1_000_000  # Example limit\n",
    "```\n",
    "\n",
    "### 6. Iterative Improvement\n",
    "\n",
    "**Process:**\n",
    "```\n",
    "1. 초기 학습 데이터셋 생성 (100개 예제)\n",
    "   ↓\n",
    "2. Fine-tune model\n",
    "   ↓\n",
    "3. 검증 데이터셋에서 테스트\n",
    "   ↓\n",
    "4. 오류 패턴 파악\n",
    "   ↓\n",
    "5. 오류 해결을 위한 예제 추가\n",
    "   ↓\n",
    "6. 2~5단계 반복\n",
    "```\n",
    "\n",
    "**Each iteration improves specific weaknesses.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72e555",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluating Custom Models\n",
    "\n",
    "### Before vs After Comparison\n",
    "\n",
    "**Test on validation set:**\n",
    "\n",
    "```python\n",
    "validation_queries = [...]  # Held-out test set\n",
    "\n",
    "# Test base model\n",
    "base_results = evaluate_model(\"gpt-4o-mini\", validation_queries)\n",
    "\n",
    "# Test fine-tuned model\n",
    "custom_results = evaluate_model(\"zava-fine-tuned\", validation_queries)\n",
    "\n",
    "# Compare\n",
    "comparison = {\n",
    "    \"Base Model\": {\n",
    "        \"Accuracy\": base_results.accuracy,\n",
    "        \"Tone Match\": base_results.tone_score,\n",
    "        \"Avg Tokens\": base_results.avg_tokens\n",
    "    },\n",
    "    \"Fine-Tuned\": {\n",
    "        \"Accuracy\": custom_results.accuracy,\n",
    "        \"Tone Match\": custom_results.tone_score,\n",
    "        \"Avg Tokens\": custom_results.avg_tokens\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "**1. 작업 성능**\n",
    "- 정확도가 향상되었습니까?\n",
    "- 답변의 관련성이 높아졌습니까?\n",
    "- 제품 추천이 더 나아졌습니까?\n",
    "\n",
    "**2. 스타일 일관성**\n",
    "- 브랜드 보이스와 일치합니까?\n",
    "- 모든 문의에서 일관된 어조를 유지합니까?\n",
    "- 적절한 격식 수준을 유지합니까?\n",
    "\n",
    "**3. 효율성**\n",
    "- 프롬프트 길이가 더 짧아졌습니까?\n",
    "- 응답 속도가 빨라졌습니까?\n",
    "- 토큰 사용량이 줄었습니까?\n",
    "\n",
    "**4. 오류 감소**\n",
    "- 잘못된 응답이 줄어들었습니까?\n",
    "- 예외 상황을 더 잘 처리합니까?\n",
    "- 오류 발생 시 더 자연스러운 응답을 제공합니까?\n",
    "\n",
    "### A/B Testing in Production\n",
    "\n",
    "```python\n",
    "# Split traffic\n",
    "def route_query(query):\n",
    "    if random.random() < 0.5:\n",
    "        return base_model.query(query)\n",
    "    else:\n",
    "        return fine_tuned_model.query(query)\n",
    "\n",
    "# Track metrics\n",
    "metrics = {\n",
    "    \"base_model\": {\"satisfaction\": [], \"latency\": []},\n",
    "    \"fine_tuned\": {\"satisfaction\": [], \"latency\": []}\n",
    "}\n",
    "\n",
    "# After 1000 queries, compare\n",
    "analyze_ab_test(metrics)\n",
    "```\n",
    "\n",
    "### Regression Testing\n",
    "\n",
    "**Ensure fine-tuning didn't break existing capabilities:**\n",
    "\n",
    "```python\n",
    "# Test suite\n",
    "regression_tests = [\n",
    "    {\"input\": \"What is 2+2?\", \"expected\": \"4\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n",
    "    # ... general knowledge tests\n",
    "]\n",
    "\n",
    "# Both models should pass\n",
    "assert all(test_model(base_model, regression_tests))\n",
    "assert all(test_model(fine_tuned, regression_tests))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e220855",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Terminology Quick Reference\n",
    "\n",
    "| Term | Simple Definition |\n",
    "|------|-------------------|\n",
    "| **Fine-Tuning** | 특정 데이터에 맞춰 모델을 추가로 학습시키는 과정 |\n",
    "| **Distillation(증류)** | 큰 모델을 모방하도록 작은 모델을 학습시키는 과정 |\n",
    "| **Few-Shot Prompting** | 프롬프트에 예시 응답을 포함하는 과정 |\n",
    "| **Supervised Fine-Tuning (SFT)** | 레이블이 지정된 입력-출력 쌍을 사용하여 미세 조정하는 과정 |\n",
    "| **JSONL** | JSON 라인 형식 - 한 줄에 하나의 JSON 객체 |\n",
    "| **Training Data** | 모델에 패턴을 학습시키는 데 사용되는 예시 |\n",
    "| **Validation Data** | 모델 성능 테스트를 위해 따로 보관해 둔 예시 |\n",
    "| **Epoch** | 학습 데이터를 한 번 완전히 학습하는 과정 |\n",
    "| **Token** | 청구에 사용되는 텍스트 단위(약 4자) |\n",
    "| **Hyperparameters** | 학습을 제어하는 ​​설정(예: 학습률) |\n",
    "| **Overfitting(과적합)** | 모델이 훈련 데이터를 암기하여 일반화하지 못함 |\n",
    "| **Teacher Model** | 증류 과정에서 소스로 사용되는 대형 모델 |\n",
    "| **Student Model** | 증류 과정에서 훈련되는 소형 모델 |\n",
    "| **Custom Grader** | 응답 품질을 평가하는 함수 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d95c68",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "이제 모델 맞춤 설정 개념을 이해했으니, 자신만의 모델을 세밀하게 조정하고 핵심 정보를 추출할 준비가 되었습니다!\n",
    "\n",
    "### Hands-On Notebooks in This Section\n",
    "\n",
    "- **`31-basic-finetuning.ipynb`** - Zava 제품 데이터를 사용하여 모델 미세 조정\n",
    "  - JSONL 형식으로 학습 데이터 준비\n",
    "  - 토큰 개수 검증 및 데이터 최적화\n",
    "  - Azure OpenAI에 미세 조정 작업 제출\n",
    "  - 미세 조정된 모델 배포 및 테스트\n",
    "  - 기본 모델과 미세 조정된 모델의 성능 비교\n",
    "\n",
    "- **`32-custom-grader.ipynb`** - 품질 관리를 위한 사용자 지정 평가기 구축\n",
    "  - 사용자 지정 채점 함수 생성\n",
    "  - 품질별로 학습 데이터 필터링\n",
    "  - 학습 데이터 품질 향상\n",
    "  - 응답이 표준을 충족하는지 검증\n",
    "\n",
    "- **`33-distill-finetuning.ipynb`** - GPT-4o 지식을 GPT-4o-mini로 정제\n",
    "  - GPT-4o에서 교사 응답 생성\n",
    "  - 학생 학습 데이터 세트 생성\n",
    "  - 교사 출력을 기반으로 GPT-4o-mini 미세 조정\n",
    "  - 학생과 교사의 품질 비교\n",
    "  - 비용 절감액 계산 증류\n",
    "\n",
    "### Recommended Learning Path\n",
    "\n",
    "1. **Start here** → 개념 이해 (this notebook)\n",
    "2. **Next** → Basic fine-tuning (`31-basic-finetuning.ipynb`)\n",
    "3. **Then** → Quality control (`32-custom-grader.ipynb`)\n",
    "4. **Advanced** → Distillation (`33-distill-finetuning.ipynb`)\n",
    "5. **After** → Move to evaluation labs (measure improvements)\n",
    "6. **Finally** → 사용자 지정 모델을 프로덕션 환경에 배포\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "For deeper understanding:\n",
    "\n",
    "- **[Fine-Tuning Guide](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning)** - Azure OpenAI fine-tuning documentation\n",
    "- **[Preparing Training Data](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=python#prepare-training-data)** - Data format and best practices\n",
    "- **[Model Distillation](https://learn.microsoft.com/azure/ai-studio/concepts/model-distillation)** - Knowledge transfer concepts\n",
    "- **[Token Optimization](https://learn.microsoft.com/azure/ai-services/openai/how-to/token-optimization)** - Reducing costs\n",
    "- **[Evaluation Metrics](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in)** - Measuring model quality\n",
    "\n",
    "---\n",
    "\n",
    "Ready to fine-tune your first model? Open `31-basic-finetuning.ipynb` to get started! 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
