{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51f9f3f",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ | Cora-For-Zava: ì •ë°€ ì¡°ì •ëœ ëª¨ë¸ ë°°í¬\n",
    "\n",
    "í™˜ì˜í•©ë‹ˆë‹¤! ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Azure SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë°€ ì¡°ì •ëœ ëª¨ë¸ì„ Azure AIì— ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ›’ Zava ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "**Cora**ëŠ” DIY ì• í˜¸ê°€ë¥¼ ìœ„í•œ í™ˆ ì¸í…Œë¦¬ì–´ ìš©í’ˆì„ íŒë§¤í•˜ëŠ” ê°€ìƒì˜ ì†Œë§¤ì—…ì²´ **Zava**ì˜ ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ì…ë‹ˆë‹¤. Zavaì˜ ì œí’ˆê³¼ ê³ ê° ìš”êµ¬ ì‚¬í•­ì„ ë” ì˜ ì´í•´í•˜ë„ë¡ ëª¨ë¸ì„ ì •ë°€ ì¡°ì •í•œ í›„, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Azure AI Foundryì— ë°°í¬í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì™„ë£Œëœ ì •ë°€ â€‹â€‹ì¡°ì • ì‘ì—… ëª©ë¡ì„ í™•ì¸í•˜ê³  ì‚¬ìš©ì ì§€ì • ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "## ğŸ¯ ì™„ì„± ëª©í‘œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ ë§ˆì¹˜ë©´ ë‹¤ìŒì„ ë‹¬ì„±í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "- âœ… ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ëª¨ë“  ë¯¸ì„¸ ì¡°ì • ì‘ì—… ëª©ë¡\n",
    "- âœ… ë°°í¬í•  ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ ì„ íƒ\n",
    "- âœ… Azure AI Foundryì— ëª¨ë¸ ë°°í¬\n",
    "- âœ… ë°°í¬ê°€ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸\n",
    "\n",
    "## ğŸ’¡ í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "- ë¯¸ì„¸ ì¡°ì • ì‘ì—… ëª©ë¡ ë° ê´€ë¦¬ ë°©ë²•\n",
    "- Azure AI Foundryì— ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ ë°°í¬ ë°©ë²•\n",
    "- ëª¨ë¸ ë°°í¬ ëª¨ë²” ì‚¬ë¡€\n",
    "- ë°°í¬ ìƒíƒœ í™•ì¸ ë°©ë²•\n",
    "\n",
    "ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ë°°í¬í•  ì¤€ë¹„ê°€ ë˜ì…¨ë‚˜ìš”? ì§€ê¸ˆ ì‹œì‘í•´ ë´…ì‹œë‹¤! ğŸš€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cd122",
   "metadata": {},
   "source": [
    "### 1. Check Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0065865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All required environment variables are set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_SUBSCRIPTION_ID\",\n",
    "    \"AZURE_RESOURCE_GROUP\",\n",
    "    \"AZURE_AI_FOUNDRY_NAME\"\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"âŒ Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"\\nPlease set these variables before continuing.\")\n",
    "else:\n",
    "    print(\"âœ… All required environment variables are set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9769d3",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Create Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dbee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Azure OpenAI client created successfully!\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=get_bearer_token_provider(\n",
    "        DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-02-01-preview\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Azure OpenAI client created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c5165",
   "metadata": {},
   "source": [
    "\n",
    "### 3. List Available Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef96b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 2 successful fine-tuning job(s):\n",
      "\n",
      "1. Job ID: ftjob-c29a542bc37e440db871ecc2b01214df\n",
      "   Model: gpt-4.1-nano-2025-04-14.ft-c29a542bc37e440db871ecc2b01214df-o3-mini-zava-tone-3a095088\n",
      "   Created: 1767793440\n",
      "   Status: succeeded\n",
      "\n",
      "2. Job ID: ftjob-25dbaf49417c425e80f41e39b73a13d7\n",
      "   Model: gpt-4o-2024-08-06.ft-25dbaf49417c425e80f41e39b73a13d7\n",
      "   Created: 1767785734\n",
      "   Status: succeeded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all fine-tuning jobs\n",
    "jobs_response = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Filter for succeeded jobs\n",
    "succeeded_jobs = [\n",
    "    job for job in jobs_response.data if job.status == \"succeeded\"]\n",
    "\n",
    "if not succeeded_jobs:\n",
    "    print(\"âŒ No successful fine-tuning jobs found.\")\n",
    "    print(\"\\nPlease complete a fine-tuning job first using 31-basic-finetuning.ipynb\")\n",
    "else:\n",
    "    print(f\"âœ… Found {len(succeeded_jobs)} successful fine-tuning job(s):\\n\")\n",
    "    for i, job in enumerate(succeeded_jobs, 1):\n",
    "        print(f\"{i}. Job ID: {job.id}\")\n",
    "        print(f\"   Model: {job.fine_tuned_model}\")\n",
    "        print(f\"   Created: {job.created_at}\")\n",
    "        print(f\"   Status: {job.status}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a565df",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Select Model to Deploy\n",
    "\n",
    "Enter a job ID from the list above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3382eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a job ID (get the model name from the job)\n",
    "# Replace with your job ID from the list above\n",
    "# job_id = \"input your finetuning job ID here\"\n",
    "job_id = \"ftjob-c29a542bc37e440db871ecc2b01214df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afff8388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selected model: gpt-4.1-nano-2025-04-14.ft-c29a542bc37e440db871ecc2b01214df-o3-mini-zava-tone-3a095088\n",
      "   From job: ftjob-c29a542bc37e440db871ecc2b01214df\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the job to get the fine-tuned model name\n",
    "job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model = job.fine_tuned_model\n",
    "\n",
    "print(f\"âœ… Selected model: {fine_tuned_model}\")\n",
    "print(f\"   From job: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eafbd",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Configure Deployment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7b00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Deployment Configuration:\n",
      "   Name: 60-zava-finetuned-1767823149\n",
      "   Model: gpt-4.1-nano-2025-04-14.ft-c29a542bc37e440db871ecc2b01214df-o3-mini-zava-tone-3a095088\n",
      "   SKU: GlobalStandard\n",
      "   Capacity: 250\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Generate unique deployment name\n",
    "timestamp = int(time.time())\n",
    "DEPLOYMENT_NAME = f\"60-zava-finetuned-{timestamp}\"\n",
    "\n",
    "# Configure deployment settings\n",
    "DEPLOYMENT = {\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model,\n",
    "            \"version\": \"1\"\n",
    "        },\n",
    "    },\n",
    "    \"sku\": {\n",
    "        # Adjust based on your needs (e.g., 250 for DeveloperTier)\n",
    "        \"capacity\": 250,\n",
    "        # \"name\": \"Standard\"  # Options: \"DeveloperTier\", \"Standard\", \"GlobalStandard\"\n",
    "        \"name\": \"GlobalStandard\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“‹ Deployment Configuration:\")\n",
    "print(f\"   Name: {DEPLOYMENT_NAME}\")\n",
    "print(f\"   Model: {fine_tuned_model}\")\n",
    "print(f\"   SKU: {DEPLOYMENT['sku']['name']}\")\n",
    "print(f\"   Capacity: {DEPLOYMENT['sku']['capacity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac98748",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Create Azure Management Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb27911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Azure Management client created successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
    "\n",
    "# Create management client for Azure Cognitive Services\n",
    "cogsvc_client = CognitiveServicesManagementClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Azure Management client created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da29cf8",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Deploy the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21349089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting deployment of 60-zava-finetuned-1767823149...\n",
      "\n",
      "âœ… Deployment request submitted!\n",
      "\n",
      "â³ Deployment is now provisioning...\n",
      "   This typically takes 3-5 minutes for small models\n"
     ]
    }
   ],
   "source": [
    "# Submit deployment request\n",
    "print(f\"ğŸš€ Starting deployment of {DEPLOYMENT_NAME}...\\n\")\n",
    "\n",
    "deployment = cogsvc_client.deployments.begin_create_or_update(\n",
    "    resource_group_name=os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    account_name=os.environ.get(\"AZURE_AI_FOUNDRY_NAME\"),\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    deployment=DEPLOYMENT,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Deployment request submitted!\")\n",
    "print(f\"\\nâ³ Deployment is now provisioning...\")\n",
    "print(f\"   This typically takes 3-5 minutes for small models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff190287",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Wait for Deployment to Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4382435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›³ï¸  Provisioning 60-zava-finetuned-1767823149\n",
      "ğŸ“Š Status: Succeeded\n",
      "â±ï¸  Elapsed time: 3 minutes 32 seconds\n",
      "\n",
      "ğŸ‰ Deployment completed successfully!\n",
      "â±ï¸  Total time: 3 minutes 32 seconds\n",
      "\n",
      "ğŸ“ Deployment Details:\n",
      "   Name: 60-zava-finetuned-1767823149\n",
      "   Model: gpt-4.1-nano-2025-04-14.ft-c29a542bc37e440db871ecc2b01214df-o3-mini-zava-tone-3a095088\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "status = deployment.status()\n",
    "\n",
    "while status not in [\"Succeeded\", \"Failed\"]:\n",
    "    deployment.wait(5)\n",
    "    status = deployment.status()\n",
    "    elapsed_min = int((time.time() - start_time) // 60)\n",
    "    elapsed_sec = int((time.time() - start_time) % 60)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f\"ğŸ›³ï¸  Provisioning {DEPLOYMENT_NAME}\")\n",
    "    print(f\"ğŸ“Š Status: {status}\")\n",
    "    print(f\"â±ï¸  Elapsed time: {elapsed_min} minutes {elapsed_sec} seconds\")\n",
    "\n",
    "# Final status\n",
    "elapsed_min = int((time.time() - start_time) // 60)\n",
    "elapsed_sec = int((time.time() - start_time) % 60)\n",
    "\n",
    "if status == \"Succeeded\":\n",
    "    print(f\"\\nğŸ‰ Deployment completed successfully!\")\n",
    "    print(f\"â±ï¸  Total time: {elapsed_min} minutes {elapsed_sec} seconds\")\n",
    "    print(f\"\\nğŸ“ Deployment Details:\")\n",
    "    print(f\"   Name: {DEPLOYMENT_NAME}\")\n",
    "    print(f\"   Model: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Deployment failed with status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfc92a",
   "metadata": {},
   "source": [
    "\n",
    "### 9. Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7be00154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/2: Testing deployed model with prompt:\n",
      "   'Can I use extension poles with your roller frames?'\n",
      "\n",
      "Response from 60-zava-finetuned-1767823149:\n",
      "At Zava, many of our roller frames are designed to be compatible with extension poles, allowing you to work more comfortably on high or low surfaces. However, itâ€™s important to check the specific model youâ€™re interested in.\n",
      "\n",
      "Here are some general tips:\n",
      "- Look for frames that have a threaded end or a universal connector, as these are typically designed to work with extension poles.\n",
      "- If youâ€™re considering a roller frame for a particular project, please consult the product details or ask a Zava associate for compatibility.\n",
      "- Many extension poles are adjustable in length and can accommodate a variety of roller frame fittings by using adapters if needed.\n",
      "\n",
      "If you can specify the particular roller frame youâ€™re considering or have additional questions about your project, Iâ€™d be glad to\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 2/2: Testing deployed model with prompt:\n",
      "   'Do you have natural bristle brushes?'\n",
      "\n",
      "Response from 60-zava-finetuned-1767823149:\n",
      "Yes, Zava offers a selection of natural bristle brushes. These brushes are ideal for a variety of finishes, such as oil-based paints, stains, and varnishes, because they help achieve a smooth and even application. If youâ€™re interested in a particular type or size of natural bristle brush, or if youâ€™d like recommendations based on your project needs, Iâ€™m here to help.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the deployed model with multiple sample prompts\n",
    "test_prompts = [\n",
    "    \"Can I use extension poles with your roller frames?\",\n",
    "    \"Do you have natural bristle brushes?\"\n",
    "]\n",
    "\n",
    "for i, test_prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"Test {i}/{len(test_prompts)}: Testing deployed model with prompt:\")\n",
    "    print(f\"   '{test_prompt}'\\n\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_NAME,  # Use the deployment name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are Cora, a polite, factual and helpful assistant for Zava, a DIY hardware store.\"},\n",
    "            {\"role\": \"user\", \"content\": test_prompt}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    print(f\"Response from {DEPLOYMENT_NAME}:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cd4ff",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "ìœ„ ë‘ ì˜ˆì‹œ ëª¨ë‘ì—ì„œ ì‘ë‹µì´ \"ì •ì¤‘í•˜ê³ , ì‚¬ì‹¤ì ì´ë©°, ë„ì›€ì´ ë˜ëŠ”\" Zava ê°€ì´ë“œë¼ì¸ì„ ì •í™•í•˜ê²Œ ë”°ë¥´ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ëª¨ë“  ì‘ë‹µì€ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "- ì²« ë¬¸ì¥ì€ í•­ìƒ ì‚¬ìš©ìì—ê²Œ ê°ì‚¬ë¥¼ í‘œí•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤(\"ì •ì¤‘í•¨\").\n",
    "- ë‹¤ìŒ ë¬¸ì¥ì€ í•­ìƒ ìœ ìµí•œ ì •ë³´ì…ë‹ˆë‹¤(\"ì‚¬ì‹¤ì \").\n",
    "- ë§ˆì§€ë§‰ ë¬¸ì¥ì€ í•­ìƒ í›„ì† ì¡°ì¹˜ë¥¼ ì œì•ˆí•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤(\"ë„ì›€\").\n",
    "\n",
    "ë˜í•œ, ëª‡ ê°€ì§€ ì˜ˆì‹œë¥¼ ì¶”ê°€í•˜ì§€ ì•Šê³ ë„ ìš°ë¦¬ê°€ ì›í•˜ë˜ ê°„ê²°í•œ ì‘ë‹µì„ ì–»ì„ ìˆ˜ ìˆì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ì¶•í•˜ê³  í† í° ë¹„ìš©ê³¼ ì²˜ë¦¬ ì§€ì—° ì‹œê°„ì„ ëª¨ë‘ ì ˆê°í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757601c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Teardown\n",
    "\n",
    "Once you are done with this lab, don't forget to tear down the infrastructure. The developer tier model will be torn down automatically (after 24 hours?) but it is better to proactively delete the resource group and release all model quota."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
